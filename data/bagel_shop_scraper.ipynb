{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose: Scrape first 3 pages of Yelp data for every single zipcode in NYC with label of \"bagel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv file with all zip codes in NYC\n",
    "\n",
    "zip_nyc = pd.read_csv(\"zipcodes_nyc.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split zipcodes into 10 groups, because we will run the scraper in smaller groups \n",
    "\n",
    "zip_split = np.array_split(zip_nyc.zip_nyc.to_list(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to contain information\n",
    "\n",
    "name = []\n",
    "phone = []\n",
    "rev_count = []\n",
    "price = []\n",
    "food_type = []\n",
    "rat = []\n",
    "add = []\n",
    "town = [] \n",
    "zip_search = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works for one url to print a dataframe with the correct columns\n",
    "\n",
    "def get_bagel_data(zips):\n",
    "    \n",
    "    for z in zips:\n",
    "        delay = np.random.choice([0,0,0,0,7,4,6,2,10,19,7,8,34,7,100,345,542])\n",
    "        print(delay)\n",
    "        print(z)\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        for i in [0,10,20]:\n",
    "            url = \"https://api.scrapingdog.com/scrape?api_key={}&url=https://www.yelp.com/search?cflt=bagels&find_loc={}&start={}\".format(os.environ['SCRAPE_API'],z,i)\n",
    "            r = requests.get(url)\n",
    "            soup = BeautifulSoup(r.content,'lxml')          \n",
    "            \n",
    "            for item in soup.select('[class*=container]'): \n",
    "                if item.find('h4'):\n",
    "                    name.append(item.find('h4').get_text())\n",
    "                    phone.append(item.select('[class*=secondaryAttributes]')[0].get_text())\n",
    "                    try:\n",
    "                        rev_count.append(item.select('[class*=reviewCount]')[0].get_text())\n",
    "                    except IndexError: rev_count.append(np.nan) \n",
    "                    try:\n",
    "                        price.append(item.select('[class*=priceRange]')[0].get_text())\n",
    "                    except IndexError: price.append(np.nan) \n",
    "                    food_type.append(item.select('[class*=priceCategory]')[0].get_text())\n",
    "                    try:\n",
    "                        rat.append(item.select('[aria-label*=rating]')[0]['aria-label'])\n",
    "                    except IndexError: rat.append(np.nan) \n",
    "                    try:\n",
    "                        add.append(item.find('address').get_text())\n",
    "                    except AttributeError:  add.append(np.nan)  \n",
    "                    town.append(item.select('[class*=margin-b1__09f24__1647o]')[0].get_text())\n",
    "                    zip_search.append(z)\n",
    "\n",
    "    df = pd.DataFrame({'name': name,'phone': phone, 'review_count':rev_count, 'price': price, 'food_type': food_type,'rating': rat ,'address': add, 'town': town, 'zip_search': zip_search})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the bagel as both csv and as a pickle file\n",
    "\n",
    "bagel_nyc_data.to_csv(date.today().strftime(\"%Y%m%d\")+\"_bagel_nyc_data_10.csv\", index = False)\n",
    "bagel_nyc_data.to_pickle(date.today().strftime(\"%Y%m%d\")+\"_bagel_nyc_data_10.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
