{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import date\n",
    "import googlemaps\n",
    "from string import printable\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose: Clean the scraped bagel data, and get longitude and latitude data from Google API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scraped bagel data\n",
    "\n",
    "bagel_data = pd.read_pickle('20210205_bagel_nyc_data_10.pkl')\n",
    "bagel_data_clean = bagel_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract phone number from column\n",
    "\n",
    "bagel_data_clean['phone'] = bagel_data_clean['phone']\\\n",
    ".str\\\n",
    ".replace(\" \",\"-\")\\\n",
    ".str\\\n",
    ".slice(start = 0, stop = 14)\n",
    "\n",
    "# Remove any any symbols in the phone number\n",
    "\n",
    "bagel_data_clean['phone'] = bagel_data_clean['phone'].str.replace('[^0-9]',\"\")\n",
    "\n",
    "# Get phone number length\n",
    "\n",
    "bagel_data_clean['phone_count'] = bagel_data_clean['phone'].str.len()\n",
    "\n",
    "# If any phone number length is not equal to 10 (indicating a wrong phone number), replace with NaN\n",
    "\n",
    "bagel_data_clean['phone']= np.where(bagel_data_clean['phone_count'] != 10, np.nan,bagel_data_clean['phone'])\n",
    "\n",
    "# Extract food type information from column\n",
    "\n",
    "bagel_data_clean['food_type'] = bagel_data_clean['food_type'].str.replace('$', '')\n",
    "\n",
    "# Transform review count to numeric\n",
    "\n",
    "bagel_data_clean['review_count'] = pd.to_numeric(bagel_data_clean['review_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any advertisement rows, which are rows that don't start with a rank number from 1-30\n",
    "\n",
    "bagel_data_clean['name_filter'] = pd.to_numeric(bagel_data_clean[\"name\"].str.slice(start=0,stop=1), errors = 'coerce')\n",
    "bagel_data_clean['name'] = bagel_data_clean['name'].str.replace('\\d+\\.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invisible characters from name \n",
    "\n",
    "bagel_data_clean['name'] = bagel_data_clean['name'].str.encode('ascii', 'ignore').str.decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates of datasets based on name of the bagel shop and the address.\n",
    "# Choose the observation with the highest review_count to break ties between duplicates\n",
    "\n",
    "final_bagel_data = bagel_data_clean[bagel_data_clean.name_filter.notnull()]\\\n",
    ".drop(['zip_search','name_filter','phone_count'], axis=1)\\\n",
    ".sort_values(['review_count'])\\\n",
    ".drop_duplicates(subset=['name','address'], keep='last')\\\n",
    ".reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to csv file\n",
    "\n",
    "final_bagel_data.to_csv(\"final_bagel_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Google Geolocation information for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Google API key for Google Geolocation information\n",
    "\n",
    "gmaps = googlemaps.Client(key=os.environ['GOOGLE_API'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with information that will be used to searched for in the Google API\n",
    "\n",
    "final_bagel_data['search'] = final_bagel_data['name'].fillna(\"\") + \" \" + \\\n",
    "final_bagel_data['address'].fillna(\"\") + \" \" + \\\n",
    "final_bagel_data['town'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply google maps API\n",
    "\n",
    "final_bagel_data[\"loc\"] = final_bagel_data[\"search\"].apply(gmaps.geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a version of the dataset with the Google Map data so that we don't have to rerun\n",
    "\n",
    "final_bagel_data.to_pickle(\"final_bagel_data_gmaps_api.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional data cleaning to separate loc column into separate columns\n",
    "\n",
    "final_bagel_data['formatted_address_gmap']= final_bagel_data[\"loc\"].apply(lambda loc: loc[0]['formatted_address'] if loc else None)\n",
    "final_bagel_data['lat_gmap']= final_bagel_data[\"loc\"].apply(lambda loc: loc[0]['geometry']['location']['lat'] if loc else None)\n",
    "final_bagel_data['lng_gmap']= final_bagel_data[\"loc\"].apply(lambda loc: loc[0]['geometry']['location']['lng'] if loc else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop additional name and formatted address duplicates (sometimes Yelp has the same store but with slightly different addresses)\n",
    "# Drop the addresses that Google couldn't find information for\n",
    "\n",
    "final_bagel_data_geo = final_bagel_data[final_bagel_data.formatted_address_gmap.str.contains('NY', na=False) == True]\\\n",
    ".sort_values(['review_count'])\\\n",
    ".drop_duplicates(subset=['name','formatted_address_gmap'], keep='last')\\\n",
    ".reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "\n",
    "final_bagel_data_geo.to_pickle(\"final_bagel_data_geo.pkl\")\n",
    "final_bagel_data_geo.to_csv(\"final_bagel_data_geo.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
